{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.11)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (15.0.2)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.16.6)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
      "Collecting tqdm\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.44.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.13.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe) (12.4.127)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow opencv-python mediapipe scikit-learn matplotlib pandas pyarrow wandb plotly tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Load parquet data into dataset_parquet for training.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # root = os.path.join(\"/\", \"kaggle\", \"input\", \"asl-signs\") \n",
    "    root = os.path.join(\".\")\n",
    "    DATA_LIMIT = 100\n",
    "    BATCH_SIZE = 8\n",
    "    VIDEO_LENGTH = 60\n",
    "    TRAIN_VAL_SPLIT = 0.9\n",
    "    WANDB_RUN = \"mediapipe-asl-dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS :  40\n",
      "EYE_LEFT :  20\n",
      "EYE_RIGHT :  20\n",
      "LEFT_HAND :  21\n",
      "RIGHT_HAND :  21\n",
      "LEFT_POSE :  5\n",
      "RIGHT_POSE :  5\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "\n",
    "EYE_LEFT = np.array([33, 7, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 471, 470, 469, 472])\n",
    "EYE_RIGHT = np.array([362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382, 476, 475, 474, 477])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n",
    "RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n",
    "\n",
    "print(\"LIPS : \",len(LIPS_IDXS0))\n",
    "print(\"EYE_LEFT : \",len(EYE_LEFT))\n",
    "print(\"EYE_RIGHT : \",len(EYE_RIGHT))\n",
    "print(\"LEFT_HAND : \",len(LEFT_HAND_IDXS0))\n",
    "print(\"RIGHT_HAND : \",len(RIGHT_HAND_IDXS0))\n",
    "print(\"LEFT_POSE : \",len(LEFT_POSE_IDXS0))\n",
    "print(\"RIGHT_POSE : \",len(RIGHT_POSE_IDXS0))\n",
    "\n",
    "all_selection = np.concatenate([LIPS_IDXS0, EYE_LEFT, EYE_RIGHT, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, LEFT_POSE_IDXS0, RIGHT_POSE_IDXS0])\n",
    "print(len(all_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code sorts out a parquet files and rearrange the order to pose,face, left-hand, right-hand\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "ids = None\n",
    "\n",
    "order_global = {\"pose\" : 10000, \"face\" : 1000, \"left_hand\" : 100, \"right_hand\" : 10}\n",
    "\n",
    "def visualize_keypoints(frames : np.ndarray, point_size : int):\n",
    "    if len(frames.shape) == 1:\n",
    "        frames = np.array([frames])\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame.reshape(-1, 3)\n",
    "        sizes = point_size * np.ones(frame.shape[0])\n",
    "\n",
    "        fig = go.Figure(data=go.Scatter(x=frame[:,0], y=2.5 - frame[:,1], mode='markers',\n",
    "                                        marker=dict(\n",
    "                                            size=sizes\n",
    "                                            )))\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(title='visualization of human keypoints',\n",
    "                        xaxis_title='',\n",
    "                        yaxis_title='',\n",
    "                        width=1000,\n",
    "                        height=1600)\n",
    "\n",
    "    fig.update_xaxes(range=[-0.2, 1.4])  # Set x-axis range from 0 to 6\n",
    "    fig.update_yaxes(range=[0, 2.5])  # Set y-axis range from 10 to 20\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def process_parquet(ds, idxes = None):\n",
    "    ret = []\n",
    "    frames_unique = sorted(np.unique(ds[\"frame\"]))\n",
    "    for i,frame in enumerate(frames_unique):\n",
    "        frame_ds = ds[ds['frame'] == frame]\n",
    "        \n",
    "        order = []\n",
    "        for el in frame_ds[\"row_id\"]:\n",
    "            _frame, part, keypoint = el.split(\"-\")\n",
    "            order.append(order_global[part] - int(keypoint))\n",
    "\n",
    "        order = np.array(order)\n",
    "        frame_ds.iloc[:, 1] = order\n",
    "        frame_ds = frame_ds.sort_values(by=\"row_id\", ascending=False)\n",
    "    \n",
    "        vals = np.array(frame_ds[[\"x\", \"y\", \"z\"]])\n",
    "        if idxes is not None:\n",
    "            vals = vals[idxes]\n",
    "    \n",
    "        vals = vals.flatten()\n",
    "\n",
    "        ret.append(vals)\n",
    "        \n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def process_parquet2(ds, idxes = None):\n",
    "    ret = []    \n",
    "    frame_size = 543\n",
    "    it = len(ds) // frame_size\n",
    "    assert it == len(ds) / frame_size\n",
    "    \n",
    "    for i in range(it):\n",
    "        vals = ds.iloc[ i * frame_size : (i + 1 ) * frame_size ]        \n",
    "        \n",
    "        if idxes is not None:          \n",
    "            vals = ds.iloc[idxes]\n",
    "                        \n",
    "        ret.append(np.array(vals[[\"x\",\"y\", \"z\"]]).flatten())\n",
    "        \n",
    "    return np.array(np.array(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '79631423.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m process_parquet(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m79631423.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m visualize_keypoints(f[\u001b[38;5;241m0\u001b[39m], point_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '79631423.parquet'"
     ]
    }
   ],
   "source": [
    "f = process_parquet(pd.read_parquet(\"79631423.parquet\"))\n",
    "visualize_keypoints(f[0], point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = process_parquet2(pd.read_parquet(\"79631423.parquet\"), idxes=all_selection)\n",
    "visualize_keypoints(f2[0], point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ASL-ds/train_landmark_files/16069/695046.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mASL-ds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_landmark_files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m16069\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m695046.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ASL-ds/train_landmark_files/16069/695046.parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet( os.path.join(\"..\", \"data\",\"ASL-ds\", \"train_landmark_files\", \"16069\", \"695046.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [00:00<00:00, 315108.95it/s]\n",
      "100%|██████████| 94477/94477 [00:00<00:00, 315050.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinality of train : 113, cardinality of validation : 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom class to load data from Parquet files for training ML models.\n",
    "class ParquetDataset(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_folder, csv_file : str, batch_size=CONFIG.BATCH_SIZE, \n",
    "                 data_limit :int= CONFIG.DATA_LIMIT, check_if_file_exists = True, \n",
    "                 preprocessing_func=None, frame_length :int = CONFIG.VIDEO_LENGTH,\n",
    "                 split : str = \"train\", train_val_split : float = CONFIG.TRAIN_VAL_SPLIT,\n",
    "                 sort_by_counts : bool = True, **kwargs\n",
    "                ):\n",
    "        super().__init__(**kwargs)\n",
    "        #taking keras sequence for .fit(), .evaluate(), .predict() methods\n",
    "        #load csv - it has the path to parquet file, and another to store label\n",
    "        self.csv_path = csv_file\n",
    "        self.root_folder = dataset_folder\n",
    "        self.batch_size = batch_size\n",
    "        #optional pre-processing function to the parquet files.\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        \n",
    "        self.csv_data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.all_files = []\n",
    "        self.not_exists = []\n",
    "        self.frame_length = frame_length\n",
    "\n",
    "        \n",
    "        for path, label in tqdm(list(zip(self.csv_data[\"path\"], self.csv_data[\"sign\"]))):\n",
    "            prop_path = os.path.join(self.root_folder, path)\n",
    "            \n",
    "            if check_if_file_exists:\n",
    "                if os.path.exists(prop_path):\n",
    "                    self.all_files.append((prop_path, label))\n",
    "                else:\n",
    "                    self.not_exists.append(prop_path)\n",
    "            else:\n",
    "                self.all_files.append((prop_path, label))\n",
    "                \n",
    "                    \n",
    "        self.all_files = np.array(self.all_files)\n",
    "        self.unique_labels = np.unique(self.all_files[:, 1])\n",
    "        self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "    \n",
    "        # sort the values by popularity\n",
    "        if sort_by_counts:\n",
    "            cnt = Counter(self.all_files[:, 1])\n",
    "            vals = []\n",
    "            \n",
    "            for i,row in enumerate(self.all_files):\n",
    "                vals.append((int(1e6 * cnt[row[1]] + self.label_2_id [row[1]]),i))\n",
    "            \n",
    "            vals = np.array(sorted(vals)[::-1])\n",
    "            self.all_files = self.all_files[vals[:,1]]\n",
    "\n",
    "        \n",
    "        if data_limit < 0:\n",
    "            train_ds, val_ds = train_test_split(self.all_files, train_size=train_val_split, random_state=42)\n",
    "        else:\n",
    "            train_ds, val_ds = train_test_split(self.all_files[:data_limit], train_size=train_val_split, random_state=42)\n",
    "            self.unique_labels = np.unique(self.all_files[:data_limit, 1])\n",
    "            self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "            \n",
    "        if split.lower() == \"train\":\n",
    "            self.dataset = train_ds\n",
    "            \n",
    "        elif split.lower() == \"val\":\n",
    "            self.dataset = val_ds \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"please specify split to be either train or val\")\n",
    "            \n",
    "        np.random.shuffle(self.dataset)\n",
    "                   \n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming each Parquet file should be one batch; adjust if necessary\n",
    "        return math.ceil(len(self.dataset) / self.batch_size)\n",
    "    \n",
    "    def get_single(self, idx):\n",
    "        # Load one file per batch\n",
    "        #take the idx value, 1st label, \n",
    "        path, label = self.dataset[idx]\n",
    "        \n",
    "        df = pd.read_parquet( path)\n",
    "        \n",
    "        # Apply preprocessing if specified\n",
    "        if self.preprocessing_func:\n",
    "            df = self.preprocessing_func(df, self.frame_length)\n",
    "        \n",
    "        one_hot_encoded_label = np.zeros(len(self.unique_labels))\n",
    "        one_hot_encoded_label[self.label_2_id[label]] = 1  \n",
    "        \n",
    "        return df, one_hot_encoded_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = [], []\n",
    "        \n",
    "        low = idx * self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.dataset))\n",
    "        \n",
    "        for i in range(low, high):\n",
    "            x, y = self.get_single(i)\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        \n",
    "        return np.array(X), np.array(Y)\n",
    "                \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle files for the next epoch\n",
    "        np.random.shuffle(self.dataset)\n",
    "\n",
    "def my_preprocessing_func(df, frame_length):\n",
    "    \n",
    "    # Define your preprocessing steps here\n",
    "    # Example: normalize numerical features\n",
    "    frames_mediapipe = process_parquet2(df, all_selection)\n",
    "    \n",
    "    current_length, num_features = frames_mediapipe.shape\n",
    "\n",
    "    if current_length >= frame_length:\n",
    "            # TODO: a better than uniform value ? Could place gaussian in the middle\n",
    "            random_start = random.randint(0, current_length - frame_length)\n",
    "            return np.nan_to_num(frames_mediapipe[random_start : (random_start + frame_length)])\n",
    "        \n",
    "    # padd the video to contain zeros \n",
    "    return np.concatenate([np.nan_to_num(frames_mediapipe), np.zeros((frame_length - current_length, num_features))], axis=0)\n",
    "    \n",
    "# Usage example\n",
    "parquet_folder_path = CONFIG.root\n",
    "train_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                check_if_file_exists = True,\n",
    "                                split=\"train\")\n",
    "\n",
    "val_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                 check_if_file_exists= True,\n",
    "                                 split=\"val\")\n",
    "\n",
    "print(f\"cardinality of train : {len(train_dataset_parquet)}, cardinality of validation : {len(val_dataset_parquet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = train_dataset_parquet[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_dataset_parquet.dataset[:, 1], bins=len(train_dataset_parquet.unique_labels))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(val_dataset_parquet.dataset[:, 1], bins=len(val_dataset_parquet.unique_labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/113 [00:00<00:21,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 60, 396) (8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:20<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through dataset took : 20.9304s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "isnans =False\n",
    "\n",
    "f = True\n",
    "labels_batches = []\n",
    "for el in tqdm(train_dataset_parquet):\n",
    "    if f:\n",
    "        print(el[0].shape, el[1].shape)\n",
    "        f = False\n",
    "    labels_batches.append(el[1])\n",
    "        \n",
    "    isnans |= np.any(np.isnan(el[0]))\n",
    "    if isnans:\n",
    "        print(\"FOUND NAN!\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Iterating through dataset took : {round( time.time() - start , 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CosineAnnealingLearningRateScheduler(Callback):\n",
    "    def __init__(self, max_lr, min_lr, T_max):\n",
    "        super(CosineAnnealingLearningRateScheduler, self).__init__()\n",
    "        self.max_lr = max_lr  # Maximum learning rate (i.e., start learning rate)\n",
    "        self.min_lr = min_lr  # Minimum learning rate\n",
    "        self.T_max = T_max    # Specifies the number of epochs per cycle\n",
    "        self.t = 0            # Current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.t += 1\n",
    "        cos = np.cos(np.pi * (self.t % self.T_max) / self.T_max)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + cos)\n",
    "\n",
    "        keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "def keras_train(model, filepath : str, max_lr = 1e-4, min_lr = 5e-5, T_max=50, epochs=100, run_name=\"\",\n",
    "                mediapipe_features = \"all\", USE_WANDB=True): \n",
    "    \n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                 monitor=\"val_categorical_accuracy\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode=\"max\",\n",
    "                                                 save_freq=\"epoch\")\n",
    "    \n",
    "    cosine_annealer = CosineAnnealingLearningRateScheduler(max_lr=max_lr,\n",
    "                                                           min_lr=min_lr,\n",
    "                                                           T_max=T_max)\n",
    "    \n",
    "    #Adam Optimizer - fixed learning rate.\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=max_lr, clipnorm=1.)\n",
    "\n",
    "    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    \n",
    "    callbacks  = [checkpoint, cosine_annealer]\n",
    "    \n",
    "    if USE_WANDB:\n",
    "        wandb.init(project=CONFIG.WANDB_RUN,\n",
    "                        name=run_name,\n",
    "                        notes=\"Model summary : \\n\" + str(model),\n",
    "                        config={\"max_lr\" : max_lr, \n",
    "                                \"min_lr\" : 5e-5, \n",
    "                                \"scheduler\" : \"cosineAnnealer\", \n",
    "                                \"epochs\" : epochs, \n",
    "                                \"T_max\" : T_max, \n",
    "                                \"train_size\" : len(train_dataset_parquet.dataset),\n",
    "                                \"val_size\" : len(val_dataset_parquet.dataset),\n",
    "                                \"unique_classes\" : len(train_dataset_parquet.unique_labels), \n",
    "                                \"video_length\" : CONFIG.VIDEO_LENGTH,\n",
    "                                \"features\" : mediapipe_features\n",
    "                                })\n",
    "        callbacks.append(WandbMetricsLogger())\n",
    "\n",
    "\n",
    "    history = model.fit(train_dataset_parquet, epochs=epochs, validation_data = val_dataset_parquet, \n",
    "                        batch_size = 8, callbacks=callbacks)\n",
    "    \n",
    "    if USE_WANDB:      \n",
    "        wandb.finish()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 396),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM1.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-Dense256-LipsEyesHandsPose\",\n",
    "           mediapipe_features=\"LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM64-Dense128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-Dense256-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(256, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM256-Dense128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=f\"LSTM256-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM128-Dense256-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM128-Dense256-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu', input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0000001), \n",
    "               activity_regularizer=l2(0.0000001)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM128_l2-Dense128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM128_l2-Dense128-Dense256-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.005), \n",
    "               activity_regularizer=l2(0.005)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM-L64-D128-D256-reg=0.005-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-Dense256-LipsEyesHandsPose_bigger_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM128-Dense128-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-Dense256-LipsEyesHandsPose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM64-Dense64-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM64-Dense64-LipsEyesHandsPose_NF\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM64-Dense128-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-LipsEyesHandsPose\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, NUM_FEATURES),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", f\"LSTM64-Dense256-LipsEyesHandsPose_NF={NUM_FEATURES}.tf\"),\n",
    "            run_name=\"LSTM64-Dense256-LipsEyesHandsPose\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 60, 1629)\n"
     ]
    }
   ],
   "source": [
    "x, y = train_dataset_parquet[0]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=embed_dim, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        print(x.shape, positions.shape)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras_nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a single transformer encoder layer.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m keras_nlp\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mTransformerEncoder(\n\u001b[0;32m      3\u001b[0m     intermediate_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a simple model containing the encoder.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras_nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a single transformer encoder layer.\n",
    "encoder = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=64, num_heads=8)\n",
    "\n",
    "# Create a simple model containing the encoder.\n",
    "input = keras.Input(shape=(10, 64))\n",
    "output = encoder(input)\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "# Call encoder on the inputs.\n",
    "input_data = np.random.uniform(size=(2, 10, 64))\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 60, 1629)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
